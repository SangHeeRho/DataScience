{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_텍스트 데이터 다루기.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbmaIeB8npOJizuUG32veY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangHeeRho/DataScience/blob/main/02_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%8B%A4%EB%A3%A8%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xjGk1PCA4Pq"
      },
      "source": [
        "BeautifulSoup 사용하여 HTML 파싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1kgunNVBmDa"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# 1) 문자열에서 soup을 생성한다.\n",
        "soup1 = BeautifulSoup(\"<HTML><HEAD><<headers>></HEAD><<body>></HTML>\")\n",
        "\n",
        "# 2) 로컬 파일에서 soup을 생성한다. -> myDoc.html 파일을 사용\n",
        "soup2 = BeautifulSoup(open(\"myDoc.html\"))\n",
        "\n",
        "# 3) 웹문서에서 soup을 생성한다 -> 크롤링의 기초\n",
        "soup3 = BeautifulSoup(urlopen(\"http://www.networksciencelab.com/\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9vGDP1PGUSr",
        "outputId": "99a69fd6-aa63-487b-aae1-8c47fa7d6205"
      },
      "source": [
        "soup1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<html><head></head><body><p>&lt;<headers>&gt;&lt;&gt;</headers></p></body></html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4aKgnT3DdBR"
      },
      "source": [
        "find(), find_all() 특정 속성 (href= 파이퍼링크 정보) 값 찾기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpSTmOjpCiOj"
      },
      "source": [
        "# http://www.networksciencelab.com/ 사이트에서 하이퍼 링크 정보 모두 가져오기\n",
        "\n",
        "with urlopen(\"http://www.networksciencelab.com/\") as doc:\n",
        "  soup = BeautifulSoup(doc)\n",
        "\n",
        "# 하이퍼 링크 추출 -> 튜플 리스트로 만드는 것 for linke에 href가 있으면 튜플로 만들어줘\n",
        "links = [(link.string, link[\"href\"])for link in soup.find_all(\"a\") if link.has_attr(\"href\")]\n",
        "\n",
        "links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp8p_P67iwcg"
      },
      "source": [
        "CSV 파일 다루기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnmy7XaHi37A"
      },
      "source": [
        "ststistics 모듈을 사용해서 나이 변수의 평균과 표준편차 구하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2miiJ4yii_1N"
      },
      "source": [
        "데이터가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfrxPEZhDEIy"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(\"/content/Demographic_Statistics_By_Zip_Code.csv\") as infile:\n",
        "  data = list(csv.reader(infile))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY_khA9rjw9w"
      },
      "source": [
        "# 첫번째 레코드에 COUNT PARTICIPANTS 데이터 인덱스 값 추출 data[0] 컬럼 값\n",
        "countParticipantsIndex = data[0].index(\"COUNT PARTICIPANTS\")\n",
        "countParticipantsIndex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3wtx3mMkeSF"
      },
      "source": [
        "# COUNT PARTICIPANTS 데이터 추출\n",
        "countParticipants = [int(row[countParticipantsIndex]) for row in data[1:]] #리스트 내포\n",
        "countParticipants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uQbKmZimm_Y"
      },
      "source": [
        "나이의 평균과 표준편차"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OLWM958mqnh",
        "outputId": "4837ca20-9367-41fd-93e3-872ddf66f779"
      },
      "source": [
        "import statistics\n",
        "\n",
        "print(statistics.mean(countParticipants), statistics.stdev(countParticipants))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17.661016949152543 43.27973735299687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06v3UOi8vbcp"
      },
      "source": [
        "자연어 처리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PKhdVTjmxEe",
        "outputId": "c39d2f62-16ba-4cae-bcd3-c308b9307775"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QSeBhI0zvgMr",
        "outputId": "590926f6-a061-4868-e51b-f38b7e063907"
      },
      "source": [
        "import nltk\n",
        "nltk.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTdm1_JLw_ap"
      },
      "source": [
        "nltk에서 영단어 온톨로지=실제언어(wordnet) 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozubFlW8vjUr",
        "outputId": "a02bb09d-7431-4aed-be07-625521609b57"
      },
      "source": [
        " # https://frhyme.github.io/python-lib/nltk-wordnet/\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmcNyZvBxIJD",
        "outputId": "78e300e9-b087-45ee-8574-a43c5caf464c"
      },
      "source": [
        "wn = nltk.corpus.wordnet # 코퍼스 리더(reader)\n",
        "\n",
        "#synset :유의어 묶음으로 단어-품사-순번 으로 구성\n",
        "wn.synsets(\"cat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('cat.n.01'),\n",
              " Synset('guy.n.01'),\n",
              " Synset('cat.n.03'),\n",
              " Synset('kat.n.01'),\n",
              " Synset('cat-o'-nine-tails.n.01'),\n",
              " Synset('caterpillar.n.02'),\n",
              " Synset('big_cat.n.01'),\n",
              " Synset('computerized_tomography.n.01'),\n",
              " Synset('cat.v.01'),\n",
              " Synset('vomit.v.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFVG_Q-Uxv5e",
        "outputId": "4af67e4d-27d6-442d-87ee-999285cf2661"
      },
      "source": [
        "wn.synset('cat.n.01').hypernyms() #hypernyms 상위어\n",
        "wn.synset('cat.n.01').hyponyms() #hyponyms 하위어"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('domestic_cat.n.01'), Synset('wildcat.n.03')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faHCYW_jy3Ax"
      },
      "source": [
        "WordNet 사용해서 synset 간 의미론적 유사도 계산하기 (0-1사이 실수)<br>\n",
        "0 이면 두 단어 서로 관계 없음<br>\n",
        "1 이면 완전한 유의어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4EBs4ahzBzf",
        "outputId": "5632e9ff-7119-4e7b-f608-29e2767c1efb"
      },
      "source": [
        "# 고양이, 링스 : 시라소니 유사도 계산\n",
        "x = wn.synset('cat.n.01') # 고양이\n",
        "y= wn.synset('lynx.n.01') # 시라소니\n",
        "\n",
        "#x,y 유사도 계산\n",
        "x.path_similarity(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UrJnjbzthJ",
        "outputId": "84308621-5356-4c28-f7e9-a4f102a27460"
      },
      "source": [
        "x = wn.synset('cat.n.01') # 고양이\n",
        "y= wn.synset('domestic_cat.n.01') # 집고양이\n",
        "x.path_similarity(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mts_nRzq0ALA",
        "outputId": "a92dda52-5ba5-4117-ab5e-43620bc7616f"
      },
      "source": [
        "x = wn.synset('cat.n.01') # 고양이\n",
        "y= wn.synset('dog.n.01') # 강아지\n",
        "x.path_similarity(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lke_Hn8B0XvH",
        "outputId": "0e98036b-02bc-4349-ecc0-76ecdb6cc00c"
      },
      "source": [
        "x = wn.synset('cat.n.01') # 고양이\n",
        "y= wn.synset('cat.n.01') # 고양이\n",
        "x.path_similarity(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kot7ejgj0JEg",
        "outputId": "1e98944a-4c72-453a-f646-3460ce311b7e"
      },
      "source": [
        "wn.synset('dog.n.01').hyponyms() # hyponyms : 하위어"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('basenji.n.01'),\n",
              " Synset('corgi.n.01'),\n",
              " Synset('cur.n.01'),\n",
              " Synset('dalmatian.n.02'),\n",
              " Synset('great_pyrenees.n.01'),\n",
              " Synset('griffon.n.02'),\n",
              " Synset('hunting_dog.n.01'),\n",
              " Synset('lapdog.n.01'),\n",
              " Synset('leonberg.n.01'),\n",
              " Synset('mexican_hairless.n.01'),\n",
              " Synset('newfoundland.n.01'),\n",
              " Synset('pooch.n.01'),\n",
              " Synset('poodle.n.01'),\n",
              " Synset('pug.n.01'),\n",
              " Synset('puppy.n.01'),\n",
              " Synset('spitz.n.01'),\n",
              " Synset('toy_dog.n.01'),\n",
              " Synset('working_dog.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwFsK68t0UK1",
        "outputId": "15b2461e-f661-44af-b915-ce3f569fa0aa"
      },
      "source": [
        "# 토큰화 (텍스트 - 단어로 쪼갠다.) -> split을 쓰나? nltk 에서 사용할 수 있음\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "word_punct = WordPunctTokenizer()\n",
        "\n",
        "text = \"}Help! :))) :[ ..... :D{\"\n",
        "\n",
        "#Tokenizer는 모든 구두점(punctuation; 문장부호)을 기준으로 분리\n",
        "# -> 이모티콘을 이용한 감성 분석 등 문장구조 깊이 분석 할 때 사용\n",
        "\n",
        "word_punct.tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['}', 'Help', '!', ':)))', ':[', '.....', ':', 'D', '{']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyraa4ZX6vRv",
        "outputId": "d8fb1c13-0f10-45d6-be1d-0097ada77a30"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH3EJeA86RMM",
        "outputId": "07c0acf4-63d9-42ff-efdb-de1df7f7746c"
      },
      "source": [
        "# 단어 토크나이저 -> 단어만 추출할때 가능\n",
        "\n",
        "nltk.word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['}', 'Help', '!', ':', ')', ')', ')', ':', '[', '...', '..', ':', 'D', '{']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Eg-F3Deq6l_v",
        "outputId": "7d7775d5-ca48-472a-adec-bca32ea090c9"
      },
      "source": [
        "#2. 단어의 대문자를 통일한다. (전부 다 대문자 or 소문자)\n",
        "#3. 불용어 제거 (stopwords 리스트 참조 THE 같은 거들 제거)\n",
        "#4. 형태소 분석(stemming) 단어를 형태소로 변환\n",
        "\n",
        "# 포터 형태소 분석기 (보수적)\n",
        "\n",
        "pstemmer = nltk.PorterStemmer()\n",
        "pstemmer.stem(\"wonderful\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wonder'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eXL4xc_I7SrN",
        "outputId": "fcfb7c02-f825-484b-d780-0fb2aab99e95"
      },
      "source": [
        "# 랭커스터 형태소 분석기 (적극적) - 더 많은 동음이의어 형태소 생산\n",
        "lstemmer = nltk.LancasterStemmer()\n",
        "lstemmer.stem(\"wonderful\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wond'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O-Hnhcr07565",
        "outputId": "a44992b3-5432-4f35-c7f2-75d0a524bdd6"
      },
      "source": [
        "# 5. 원형 추출\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "lemmatizer.lemmatize(\"wonderful\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wonderful'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmFirazB8FqV",
        "outputId": "15025e92-b4d0-480a-b30b-d70bcaa31ab5"
      },
      "source": [
        "# 그외 품사 태깅\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag([\"beautiful\",\"world\"]) # JJ adjective(형용사), NN noun(명사)\n",
        "\n",
        "# https://happygrammer.github.io/nlp/postag-set/ 참조"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beautiful', 'JJ'), ('world', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQVnRPhr88oP"
      },
      "source": [
        "# http://www.networksciencelab.com 사이트에서 하이퍼 링크 정보 모두 가져오기\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "\n",
        "with urlopen(\"http://www.networksciencelab.com/\") as doc:\n",
        "  soup = BeautifulSoup(doc)\n",
        "\n",
        "# 하이퍼 링크 추출 -> 튜플 리스트로 만드는 것 for linke에 href가 있으면 튜플로 만들어줘\n",
        "links = [(link.string, link[\"href\"])for link in soup.find_all(\"a\") if link.has_attr(\"href\")]\n",
        "\n",
        "# 책 제목만 추출\n",
        "html_text = [i[0] for i in links]\n",
        "html_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "qUwdtnQiANaj",
        "outputId": "052bcfe7-5c61-40e8-fa52-e4f0a23b4476"
      },
      "source": [
        "# None 데이터 제거 -> 리스트에서 하나의 텍스트로 변환\n",
        "html_text = \" \".join(html_text[2:])\n",
        "html_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DZPYDS DZCNAPY Networks of Music Groups as Success Predictors Network Science Workshop Resilience in Transaction-Oriented Networks Peer Ratings in Massive Online Social Networks Semantic Networks of Interests in Online NSSI Communities Towards an Ideal Store D.Zinoviev, \"Analyzing Cultural Domains with Python,\" D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\" D.Zinoviev, \"The Pain of Complexity,\" D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\" D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\" D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\" D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\" D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\" D.Zinoviev, \"Information diffusion in social networks,\" D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\" D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\" D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\" D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\" D.Zinoviev, \"Topology and Geometry of Online Social Networks,\" Vixi: The Game of Meaning Evgenia Cherkasova All Characters from War and Peace by L.Tolstoy Mapping the Bible: Social Networks in the Holy Book FIFA World Cup 2014: Who Beat Whom? The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook Email Suffolk University Google Scholar LinkedIn Academia.edu ResearchGate'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVXGMsjB-KES"
      },
      "source": [
        "# 하나의 텍스트 -> index.html 파일로 저장\n",
        "html_file = open(\"index.html\", 'w')\n",
        "html_file.write(html_text)\n",
        "html_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdwQIksdWuPt"
      },
      "source": [
        "index.html 파일에서(불용어 제외) 가장 많이 등장한 단어 원형 찾아보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXIuyKwr-vPr"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import LancasterStemmer\n",
        "\n",
        "# 형태소 분류기를 생성한다.\n",
        "ls = nltk.LancasterStemmer()\n",
        "\n",
        "# 파일을 읽고 soup을 만든다.\n",
        "with open(\"/content/index.html\") as infile:\n",
        "  soup = BeautifulSoup(infile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BufxETJeYjA8",
        "outputId": "c0cb33be-cd99-4662-9e8f-817a64bc8466"
      },
      "source": [
        "soup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<html><body><p>DZPYDS DZCNAPY Networks of Music Groups as Success Predictors Network Science Workshop Resilience in Transaction-Oriented Networks Peer Ratings in Massive Online Social Networks Semantic Networks of Interests in Online NSSI Communities Towards an Ideal Store D.Zinoviev, \"Analyzing Cultural Domains with Python,\" D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\" D.Zinoviev, \"The Pain of Complexity,\" D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\" D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\" D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\" D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\" D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\" D.Zinoviev, \"Information diffusion in social networks,\" D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\" D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\" D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\" D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\" D.Zinoviev, \"Topology and Geometry of Online Social Networks,\" Vixi: The Game of Meaning Evgenia Cherkasova All Characters from War and Peace by L.Tolstoy Mapping the Bible: Social Networks in the Holy Book FIFA World Cup 2014: Who Beat Whom? The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook Email Suffolk University Google Scholar LinkedIn Academia.edu ResearchGate</p></body></html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tah_wKpYjfK"
      },
      "source": [
        "soup.txt # BeautifulSoup이라고 불러왔기 때문에 바로 불러올 수 있음 (beautifulsoup을 안썼으면 꺽새 등등 했어야함)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRxg6QcTYkXG"
      },
      "source": [
        "# 1) 텍스트 추출 -> 토큰화 ***abc****하면 안됨\n",
        "words = nltk.word_tokenize(soup.text)\n",
        "words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3LjAg1aN2t"
      },
      "source": [
        "# 2) 단어를 소문자로 변환\n",
        "words = [w.lower() for w in words]\n",
        "words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5YM9BqMdS-O",
        "outputId": "a95ba223-e09b-40c3-8ace-6989c726b7cc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-txuejSxa7hk"
      },
      "source": [
        "# 3) 불용어를 제거하고 단어의 형태소를 추출\n",
        "# 3-1) 불용어 제거 stopwords.words(\"english\")\n",
        "# 3-2) 특수기호 제거 isalnum() 문자열이 알파벳([a-zA-Z])과 숫자([0-9])로만 구성\n",
        "words = [ls.stem(w) for w in words if w not in stopwords.words(\"english\") and w.isalnum()] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06bbzo_TdOAa",
        "outputId": "fddfaeef-ac3e-4454-ad97-68ae43aa26d4"
      },
      "source": [
        "# 4) 가장 빈번하게 등장하는 단어 10개 추출\n",
        "freqs = Counter(words)\n",
        "print(freqs.most_common(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('network', 16), ('soc', 8), ('onlin', 7), ('inform', 4), ('gam', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ps3_YX5dxFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}